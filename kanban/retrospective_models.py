"""
AI-Powered Retrospective Generator Models
Captures organizational learning, tracks improvements across projects
"""

from django.db import models
from django.contrib.auth.models import User
from django.core.validators import MinValueValidator, MaxValueValidator
from django.utils import timezone
from django.db.models import Avg, Count, Sum, Q
from decimal import Decimal


class ProjectRetrospective(models.Model):
    """
    AI-generated retrospective analysis after sprint/project completion
    Captures what went well, what didn't, and lessons learned
    """
    RETROSPECTIVE_TYPE_CHOICES = [
        ('sprint', 'Sprint Retrospective'),
        ('project', 'Project Retrospective'),
        ('milestone', 'Milestone Retrospective'),
        ('quarterly', 'Quarterly Review'),
    ]
    
    STATUS_CHOICES = [
        ('draft', 'Draft'),
        ('generated', 'Generated by AI'),
        ('reviewed', 'Reviewed by Team'),
        ('finalized', 'Finalized'),
        ('archived', 'Archived'),
    ]
    
    board = models.ForeignKey('Board', on_delete=models.CASCADE, related_name='retrospectives')
    
    # Retrospective info
    title = models.CharField(max_length=200, help_text="Retrospective title")
    retrospective_type = models.CharField(max_length=20, choices=RETROSPECTIVE_TYPE_CHOICES, default='sprint')
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='draft')
    
    # Time period covered
    period_start = models.DateField(help_text="Start date of period being analyzed")
    period_end = models.DateField(help_text="End date of period being analyzed")
    
    # Project metrics collected
    metrics_snapshot = models.JSONField(
        default=dict,
        help_text="Snapshot of key metrics: tasks completed, velocity, quality, etc."
    )
    
    # AI-generated analysis
    what_went_well = models.TextField(
        blank=True,
        help_text="AI-identified positive aspects and successes"
    )
    what_needs_improvement = models.TextField(
        blank=True,
        help_text="AI-identified challenges and areas for improvement"
    )
    lessons_learned = models.JSONField(
        default=list,
        help_text="List of lessons learned with categories and priorities"
    )
    key_achievements = models.JSONField(
        default=list,
        help_text="Notable achievements and milestones"
    )
    challenges_faced = models.JSONField(
        default=list,
        help_text="Key challenges encountered with impact assessment"
    )
    
    # Improvement recommendations
    improvement_recommendations = models.JSONField(
        default=list,
        help_text="AI-generated actionable improvement recommendations"
    )
    
    # Team sentiment analysis
    overall_sentiment_score = models.DecimalField(
        max_digits=3,
        decimal_places=2,
        blank=True,
        null=True,
        validators=[MinValueValidator(0), MaxValueValidator(1)],
        help_text="AI-calculated sentiment score (0=negative, 1=positive)"
    )
    team_morale_indicator = models.CharField(
        max_length=20,
        choices=[
            ('low', 'Low'),
            ('moderate', 'Moderate'),
            ('high', 'High'),
            ('excellent', 'Excellent'),
        ],
        blank=True,
        null=True
    )
    
    # Performance comparison
    previous_retrospective = models.ForeignKey(
        'self',
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='subsequent_retrospectives',
        help_text="Link to previous retrospective for trend analysis"
    )
    performance_trend = models.CharField(
        max_length=20,
        choices=[
            ('improving', 'Improving'),
            ('stable', 'Stable'),
            ('declining', 'Declining'),
            ('insufficient_data', 'Insufficient Data'),
        ],
        default='insufficient_data'
    )
    
    # AI generation metadata
    ai_generated_at = models.DateTimeField(
        blank=True,
        null=True,
        help_text="When AI analysis was performed"
    )
    ai_confidence_score = models.DecimalField(
        max_digits=3,
        decimal_places=2,
        default=0.75,
        validators=[MinValueValidator(0), MaxValueValidator(1)],
        help_text="AI confidence in the analysis (0-1)"
    )
    ai_model_used = models.CharField(
        max_length=50,
        default='gemini-2.5-flash',
        help_text="AI model used for generation"
    )
    
    # Human input
    team_notes = models.TextField(
        blank=True,
        help_text="Additional notes from team discussion"
    )
    team_feedback_on_ai = models.TextField(
        blank=True,
        help_text="Team feedback on AI-generated insights"
    )
    
    # Ownership and tracking
    created_by = models.ForeignKey(
        User,
        on_delete=models.CASCADE,
        related_name='created_retrospectives'
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    finalized_by = models.ForeignKey(
        User,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='finalized_retrospectives'
    )
    finalized_at = models.DateTimeField(blank=True, null=True)
    
    # Meeting context (if generated from meeting)
    meeting_transcript = models.ForeignKey(
        'MeetingTranscript',
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='retrospectives',
        help_text="Link to retrospective meeting transcript if applicable"
    )
    
    class Meta:
        ordering = ['-period_end', '-created_at']
        verbose_name = 'Project Retrospective'
        verbose_name_plural = 'Project Retrospectives'
        indexes = [
            models.Index(fields=['board', '-period_end']),
            models.Index(fields=['retrospective_type', 'status']),
            models.Index(fields=['-created_at']),
        ]
    
    def __str__(self):
        return f"{self.title} ({self.period_start} to {self.period_end})"
    
    @property
    def duration_days(self):
        """Calculate duration of retrospective period"""
        return (self.period_end - self.period_start).days + 1
    
    @property
    def is_finalized(self):
        """Check if retrospective is finalized"""
        return self.status == 'finalized'
    
    def finalize(self, user):
        """Mark retrospective as finalized"""
        self.status = 'finalized'
        self.finalized_by = user
        self.finalized_at = timezone.now()
        self.save()


class LessonLearned(models.Model):
    """
    Individual lessons learned from retrospectives
    Tracked over time to measure if learning is applied
    """
    CATEGORY_CHOICES = [
        ('process', 'Process Improvement'),
        ('technical', 'Technical'),
        ('communication', 'Communication'),
        ('planning', 'Planning & Estimation'),
        ('quality', 'Quality Assurance'),
        ('teamwork', 'Teamwork & Collaboration'),
        ('tools', 'Tools & Technology'),
        ('risk_management', 'Risk Management'),
        ('customer', 'Customer Relations'),
        ('other', 'Other'),
    ]
    
    PRIORITY_CHOICES = [
        ('low', 'Low - Nice to have'),
        ('medium', 'Medium - Should implement'),
        ('high', 'High - Must implement'),
        ('critical', 'Critical - Immediate action'),
    ]
    
    STATUS_CHOICES = [
        ('identified', 'Identified'),
        ('planned', 'Action Planned'),
        ('in_progress', 'In Progress'),
        ('implemented', 'Implemented'),
        ('validated', 'Validated/Successful'),
        ('not_applicable', 'No Longer Applicable'),
    ]
    
    retrospective = models.ForeignKey(
        ProjectRetrospective,
        on_delete=models.CASCADE,
        related_name='lessons'
    )
    board = models.ForeignKey('Board', on_delete=models.CASCADE, related_name='lessons_learned')
    
    # Lesson details
    title = models.CharField(max_length=200, help_text="Brief lesson title")
    description = models.TextField(help_text="Detailed description of the lesson")
    category = models.CharField(max_length=30, choices=CATEGORY_CHOICES)
    priority = models.CharField(max_length=20, choices=PRIORITY_CHOICES, default='medium')
    
    # Context
    trigger_event = models.TextField(
        blank=True,
        help_text="What triggered this lesson? (event, problem, success)"
    )
    impact_description = models.TextField(
        blank=True,
        help_text="Impact this lesson had on the project"
    )
    
    # Action items
    recommended_action = models.TextField(
        help_text="Recommended action to apply this lesson"
    )
    action_owner = models.ForeignKey(
        User,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='owned_lessons',
        help_text="Person responsible for implementing"
    )
    
    # Status tracking
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='identified')
    implementation_date = models.DateField(
        blank=True,
        null=True,
        help_text="When action was implemented"
    )
    validation_date = models.DateField(
        blank=True,
        null=True,
        help_text="When improvement was validated"
    )
    
    # Impact measurement
    expected_benefit = models.TextField(
        blank=True,
        help_text="Expected benefit if implemented"
    )
    actual_benefit = models.TextField(
        blank=True,
        help_text="Actual measured benefit after implementation"
    )
    success_metrics = models.JSONField(
        default=list,
        blank=True,
        help_text="Metrics to measure success: [{'metric': 'velocity', 'before': 10, 'after': 15}]"
    )
    
    # AI metadata
    ai_suggested = models.BooleanField(
        default=False,
        help_text="Was this lesson AI-identified?"
    )
    ai_confidence = models.DecimalField(
        max_digits=3,
        decimal_places=2,
        blank=True,
        null=True,
        validators=[MinValueValidator(0), MaxValueValidator(1)]
    )
    
    # Recurrence tracking
    is_recurring_issue = models.BooleanField(
        default=False,
        help_text="Has this lesson appeared in multiple retrospectives?"
    )
    recurrence_count = models.IntegerField(
        default=1,
        help_text="Number of times this type of lesson has occurred"
    )
    related_lessons = models.ManyToManyField(
        'self',
        blank=True,
        symmetrical=True,
        help_text="Related lessons from other retrospectives"
    )
    
    # Metadata
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['-priority', '-created_at']
        verbose_name = 'Lesson Learned'
        verbose_name_plural = 'Lessons Learned'
        indexes = [
            models.Index(fields=['board', 'status']),
            models.Index(fields=['category', 'priority']),
            models.Index(fields=['retrospective']),
        ]
    
    def __str__(self):
        return f"{self.title} [{self.get_priority_display()}]"
    
    def mark_implemented(self, user):
        """Mark lesson as implemented"""
        self.status = 'implemented'
        self.implementation_date = timezone.now().date()
        self.save()
    
    def mark_validated(self, actual_benefit=None):
        """Mark lesson as validated/successful"""
        self.status = 'validated'
        self.validation_date = timezone.now().date()
        if actual_benefit:
            self.actual_benefit = actual_benefit
        self.save()
    
    @property
    def days_since_identified(self):
        """Days since lesson was identified"""
        return (timezone.now().date() - self.created_at.date()).days
    
    @property
    def is_overdue(self):
        """Check if high/critical priority lesson hasn't been acted on"""
        if self.priority in ['high', 'critical'] and self.status == 'identified':
            return self.days_since_identified > 30
        return False


class ImprovementMetric(models.Model):
    """
    Track improvement metrics over time across retrospectives
    Measures organizational learning and continuous improvement
    """
    METRIC_TYPE_CHOICES = [
        ('velocity', 'Team Velocity'),
        ('quality', 'Quality Score'),
        ('cycle_time', 'Cycle Time'),
        ('defect_rate', 'Defect Rate'),
        ('estimation_accuracy', 'Estimation Accuracy'),
        ('team_satisfaction', 'Team Satisfaction'),
        ('customer_satisfaction', 'Customer Satisfaction'),
        ('technical_debt', 'Technical Debt'),
        ('automation_coverage', 'Automation Coverage'),
        ('deployment_frequency', 'Deployment Frequency'),
        ('custom', 'Custom Metric'),
    ]
    
    board = models.ForeignKey('Board', on_delete=models.CASCADE, related_name='improvement_metrics')
    retrospective = models.ForeignKey(
        ProjectRetrospective,
        on_delete=models.CASCADE,
        related_name='metrics'
    )
    
    # Metric details
    metric_type = models.CharField(max_length=30, choices=METRIC_TYPE_CHOICES)
    metric_name = models.CharField(max_length=100, help_text="Display name for metric")
    description = models.TextField(blank=True, help_text="What this metric measures")
    
    # Values
    metric_value = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        help_text="Current metric value"
    )
    previous_value = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        blank=True,
        null=True,
        help_text="Previous period's value"
    )
    target_value = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        blank=True,
        null=True,
        help_text="Target/goal value"
    )
    
    # Change analysis
    change_amount = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        blank=True,
        null=True,
        help_text="Absolute change from previous value"
    )
    change_percentage = models.DecimalField(
        max_digits=6,
        decimal_places=2,
        blank=True,
        null=True,
        help_text="Percentage change from previous value"
    )
    trend = models.CharField(
        max_length=20,
        choices=[
            ('improving', 'Improving'),
            ('stable', 'Stable'),
            ('declining', 'Declining'),
            ('no_data', 'No Previous Data'),
        ],
        default='no_data'
    )
    
    # Context
    unit_of_measure = models.CharField(
        max_length=50,
        default='points',
        help_text="Unit (e.g., 'tasks', 'hours', 'percentage', 'score')"
    )
    higher_is_better = models.BooleanField(
        default=True,
        help_text="Is higher value better? (False if lower is better)"
    )
    
    # Metadata
    measured_at = models.DateField(help_text="Date when metric was measured")
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-measured_at', 'metric_type']
        verbose_name = 'Improvement Metric'
        verbose_name_plural = 'Improvement Metrics'
        indexes = [
            models.Index(fields=['board', 'metric_type', '-measured_at']),
            models.Index(fields=['retrospective']),
        ]
    
    def __str__(self):
        return f"{self.metric_name}: {self.metric_value} {self.unit_of_measure}"
    
    def calculate_change(self):
        """Calculate change from previous value"""
        if self.previous_value is not None:
            self.change_amount = self.metric_value - self.previous_value
            
            if self.previous_value != 0:
                self.change_percentage = (self.change_amount / abs(self.previous_value)) * 100
            
            # Determine trend
            if abs(self.change_percentage or 0) < 5:
                self.trend = 'stable'
            elif self.change_amount > 0:
                self.trend = 'improving' if self.higher_is_better else 'declining'
            else:
                self.trend = 'declining' if self.higher_is_better else 'improving'
    
    def save(self, *args, **kwargs):
        """Override save to auto-calculate changes"""
        self.calculate_change()
        super().save(*args, **kwargs)
    
    @property
    def is_meeting_target(self):
        """Check if metric is meeting target"""
        if self.target_value is None:
            return None
        
        if self.higher_is_better:
            return self.metric_value >= self.target_value
        else:
            return self.metric_value <= self.target_value


class RetrospectiveActionItem(models.Model):
    """
    Actionable items from retrospectives
    Tracks follow-up actions and their completion
    """
    ACTION_TYPE_CHOICES = [
        ('process_change', 'Process Change'),
        ('tool_adoption', 'Tool Adoption'),
        ('training', 'Training/Learning'),
        ('documentation', 'Documentation'),
        ('technical_improvement', 'Technical Improvement'),
        ('team_building', 'Team Building'),
        ('communication', 'Communication Enhancement'),
        ('other', 'Other'),
    ]
    
    STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('in_progress', 'In Progress'),
        ('completed', 'Completed'),
        ('blocked', 'Blocked'),
        ('cancelled', 'Cancelled'),
    ]
    
    retrospective = models.ForeignKey(
        ProjectRetrospective,
        on_delete=models.CASCADE,
        related_name='action_items'
    )
    board = models.ForeignKey('Board', on_delete=models.CASCADE, related_name='retrospective_actions')
    
    # Action details
    title = models.CharField(max_length=200, help_text="Action item title")
    description = models.TextField(help_text="Detailed description of action")
    action_type = models.CharField(max_length=30, choices=ACTION_TYPE_CHOICES)
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    
    # Assignment and ownership
    assigned_to = models.ForeignKey(
        User,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='assigned_retrospective_actions'
    )
    stakeholders = models.ManyToManyField(
        User,
        blank=True,
        related_name='stakeholder_retrospective_actions',
        help_text="Other people involved in this action"
    )
    
    # Timeline
    target_completion_date = models.DateField(
        blank=True,
        null=True,
        help_text="Target date for completion"
    )
    actual_completion_date = models.DateField(
        blank=True,
        null=True,
        help_text="Actual completion date"
    )
    
    # Priority and impact
    priority = models.CharField(
        max_length=20,
        choices=[
            ('low', 'Low'),
            ('medium', 'Medium'),
            ('high', 'High'),
            ('critical', 'Critical'),
        ],
        default='medium'
    )
    expected_impact = models.TextField(
        blank=True,
        help_text="Expected impact if completed"
    )
    actual_impact = models.TextField(
        blank=True,
        help_text="Actual measured impact"
    )
    
    # Blocking information
    blocked_reason = models.TextField(
        blank=True,
        help_text="Reason why action is blocked"
    )
    blocked_date = models.DateField(
        blank=True,
        null=True
    )
    
    # Progress tracking
    progress_percentage = models.IntegerField(
        default=0,
        validators=[MinValueValidator(0), MaxValueValidator(100)]
    )
    progress_notes = models.TextField(
        blank=True,
        help_text="Notes on progress and updates"
    )
    
    # Related data
    related_lesson = models.ForeignKey(
        LessonLearned,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='action_items',
        help_text="Related lesson learned"
    )
    related_task = models.ForeignKey(
        'Task',
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='retrospective_actions',
        help_text="Related project task"
    )
    
    # AI metadata
    ai_suggested = models.BooleanField(default=False)
    ai_confidence = models.DecimalField(
        max_digits=3,
        decimal_places=2,
        blank=True,
        null=True,
        validators=[MinValueValidator(0), MaxValueValidator(1)]
    )
    
    # Metadata
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['-priority', 'target_completion_date', '-created_at']
        verbose_name = 'Retrospective Action Item'
        verbose_name_plural = 'Retrospective Action Items'
        indexes = [
            models.Index(fields=['retrospective', 'status']),
            models.Index(fields=['board', 'assigned_to']),
            models.Index(fields=['status', 'priority']),
        ]
    
    def __str__(self):
        return f"{self.title} [{self.get_status_display()}]"
    
    @property
    def is_overdue(self):
        """Check if action item is overdue"""
        if self.target_completion_date and self.status not in ['completed', 'cancelled']:
            return timezone.now().date() > self.target_completion_date
        return False
    
    @property
    def days_until_due(self):
        """Days until target completion date"""
        if self.target_completion_date and self.status not in ['completed', 'cancelled']:
            delta = self.target_completion_date - timezone.now().date()
            return delta.days
        return None
    
    def mark_completed(self, actual_impact=None):
        """Mark action as completed"""
        self.status = 'completed'
        self.actual_completion_date = timezone.now().date()
        self.progress_percentage = 100
        if actual_impact:
            self.actual_impact = actual_impact
        self.save()


class RetrospectiveTrend(models.Model):
    """
    Aggregated trends across multiple retrospectives
    Shows organizational learning and improvement over time
    """
    board = models.ForeignKey('Board', on_delete=models.CASCADE, related_name='retrospective_trends')
    
    # Time period
    analysis_date = models.DateField(auto_now_add=True, help_text="When trend analysis was performed")
    period_type = models.CharField(
        max_length=20,
        choices=[
            ('quarterly', 'Quarterly'),
            ('yearly', 'Yearly'),
            ('all_time', 'All Time'),
        ],
        default='quarterly'
    )
    
    # Retrospective count
    retrospectives_analyzed = models.IntegerField(
        default=0,
        help_text="Number of retrospectives included in analysis"
    )
    
    # Aggregate metrics
    total_lessons_learned = models.IntegerField(default=0)
    lessons_implemented = models.IntegerField(default=0)
    lessons_validated = models.IntegerField(default=0)
    implementation_rate = models.DecimalField(
        max_digits=5,
        decimal_places=2,
        default=0,
        help_text="Percentage of lessons implemented"
    )
    
    total_action_items = models.IntegerField(default=0)
    action_items_completed = models.IntegerField(default=0)
    completion_rate = models.DecimalField(
        max_digits=5,
        decimal_places=2,
        default=0,
        help_text="Percentage of actions completed"
    )
    
    # Recurring issues
    recurring_issues = models.JSONField(
        default=list,
        help_text="Issues that keep appearing: [{'issue': 'description', 'count': 3}]"
    )
    top_improvement_categories = models.JSONField(
        default=list,
        help_text="Most common improvement categories"
    )
    
    # Performance trends
    velocity_trend = models.CharField(
        max_length=20,
        choices=[
            ('improving', 'Improving'),
            ('stable', 'Stable'),
            ('declining', 'Declining'),
        ],
        blank=True,
        null=True
    )
    quality_trend = models.CharField(
        max_length=20,
        choices=[
            ('improving', 'Improving'),
            ('stable', 'Stable'),
            ('declining', 'Declining'),
        ],
        blank=True,
        null=True
    )
    
    # AI insights
    ai_insights = models.TextField(
        blank=True,
        help_text="AI-generated insights about trends"
    )
    key_recommendations = models.JSONField(
        default=list,
        help_text="Top recommendations based on trends"
    )
    
    # Metadata
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-analysis_date']
        verbose_name = 'Retrospective Trend'
        verbose_name_plural = 'Retrospective Trends'
        indexes = [
            models.Index(fields=['board', '-analysis_date']),
        ]
    
    def __str__(self):
        return f"{self.board.name} Trends - {self.get_period_type_display()} ({self.analysis_date})"
    
    def calculate_rates(self):
        """Calculate implementation and completion rates"""
        if self.total_lessons_learned > 0:
            self.implementation_rate = (self.lessons_implemented / self.total_lessons_learned) * 100
        
        if self.total_action_items > 0:
            self.completion_rate = (self.action_items_completed / self.total_action_items) * 100
    
    def save(self, *args, **kwargs):
        """Override save to auto-calculate rates"""
        self.calculate_rates()
        super().save(*args, **kwargs)
